%% -*- mode: erlang -*-

[
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 %% SASL config
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

 {sasl, [
	 {sasl_error_logger, {file, "priv/log/sasl-error.log"}},
	 {errlog_type, error},
	 {error_logger_mf_dir, "priv/log/sasl"},      % Log directory
	 {error_logger_mf_maxbytes, 10485760},   % 10 MB max file size
	 {error_logger_mf_maxfiles, 5}           % 5 files max
	]
 },
 {ebot, [

	 %% !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
	 %% see EBOT options in ebot.app and add your changes here! 
	 %% !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

	 %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	 %% CACHE
	 %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	 %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	 %% DATABASE
	 %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	 %%
	 %% you need to set the db backend (COUCHDB or RIAK)
	 %% in src/ebot.hrl file
	 {db_hostname, "127.0.0.1"},
	 %% COUCHDB
	 {db_port, 5984},
	 %% RIAK 
	 %% {db_port, 8087},

	 %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	 %% MQ
	 %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	 %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	 %% WEB
	 %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	 %% -------------------------------------------------------------------------------------------------
	 %% normalize_url_list
	 %% -------------------------------------------------------------------------------------------------
	 %%
	 %% {normalize_url_list, [{RE,  NormalizeUrlOptions},..]}
	 %%
	 %% options of normalize_url : 
	 %%    add_final_slash
	 %%    to_lower_case : urls are case insensive and some web pages have links with some uppercase letters..
	 %%    without_internal_links
	 %%    without_queries,
	 %%    {max_depth, 2}
	 %%          the url path will be truncated to a max_depth path 
	 %%          http://www.redaelli.org/matteo/blog/a/ ->  http://www.redaelli.org/matteo/blog/
	 %%          should be the same as "tot_new_urls_queues" in ebot_mq.conf
	 %%	    you should also start at least one crawler for depth in [0,max_depth]. see "crawler_pools" in this file
	 %%    (TODO)  {remove_filename, false}
	 {normalize_url_list, 
	  [
	   %% {\\.com/", 
	   %%  [	
	   %% 	{plugin, ebot_url_util, url_domain},
	   %% 	add_final_slash,
	   %% 	to_lower_case
	   %%  ]
	   %% },

  
	   %% default setting for normalize_url
	   %% rememeber, at least one regexp must match all urls
	   %% "." should be used
	   {".", 
	    [
	     %% -------------------------------------------------------------------
	     %% {plugin, Module, Function/1}
	     %% -------------------------------------------------------------------
	     %% you can call a custom module:function(Url) for normaling urls
		  
	     %% are you interested only in domain homepages?
	     %% {plugin, ebot_url_util, url_domain},
		  
	     %% -------------------------------------------------------------------
	     %% {replace_string, [{from,to},..]}
	     %% -------------------------------------------------------------------	
	     {replace_string, [
			       %% http://www.gettyre.it/motoweb/XXX;jsessionid=250485C.sae_1
			       {";[A-Za-z0-9]+=[^&;?]+", ""},
			       %% some sites have newlines in url links: 
			       %% see http://opensource.linux-mirror.org/index.php
			       %% TODO maybe it still doesn t work
			       {"\n",""},
			       %% http://github.com/dizzyd/ibrowse
			       {"&quot\$",""}
			      ]},
	     %% -------------------------------------------------------------------
	     %% add_final_slash
	     %% -------------------------------------------------------------------
	     %% example: http://www.redaelli.org => http://www.redaelli.org/
	     add_final_slash,
	     
	     %% -------------------------------------------------------------------
	     %% {max_depth, 3}
	     %% -------------------------------------------------------------------
	     %% paths > max_depth are truncated to max_deth
	     %% for instance, if {max_depth,0}
	     %% http://www.redaelli.org/matteo/ => http://www.redaelli.org/
	     {max_depth, 2}, 
				
	     %% -------------------------------------------------------------------
	     %% to_lower_case
	     %% -------------------------------------------------------------------
	     %% web urls are case insensitive but not the database!
	     %% it is safer to lowecase urls
	     to_lower_case,
	     
	     %% -------------------------------------------------------------------
	     %% without_internal_links
	     %% -------------------------------------------------------------------
	     %% internal links (#) are removed
	     without_internal_links,
	     
	     %% -------------------------------------------------------------------
	     %% without_queries
	     %% -------------------------------------------------------------------
	     %% parameters, like ?a=1&b=3, are removed from urls
	     without_queries
	    ]}%% end default
	  ] % end list of {regexp, ListOptions}
	 }, %% end normalize_url
	 
	 %% -------------------------------------------------------------------------------------------------
	 %% tobe_saved_headers
	 %% -------------------------------------------------------------------------------------------------
	 %% headers (if exist) that will be saved in the database
	 {tobe_saved_headers, 
	  [
	   <<"content-length">>,
	   <<"content-type">>,
	   <<"server">>,
	   <<"x-powered-by">>
	  ]},
	 
	 %% -------------------------------------------------------------------------------------------------
	 %% mime_any_regexp
	 %% -------------------------------------------------------------------------------------------------
	 %%
	 %% the url will be analyzed if at least one regexp will be satisfied
	 %%
	 %% at least one regexp must be defined
	 
	 {mime_any_regexps, [
			     {match,   "^text/"}
			    ]
	 },

	 %% -------------------------------------------------------------------------------------------------
	 %% url_all_regexps
	 %% -------------------------------------------------------------------------------------------------
	 %%
	 %% the url will be analyzed if ALL regexps will be satisfied
	 %%
	 {url_all_regexps, [
			    {match, "^http://"},
			    %% {nomatch, "^https"},
			    {nomatch, "//.+//"},
			    {nomatch, "/bugs/"},
			    {nomatch, "viewcvs\\.cgi"},

			    %% Skipping Apache.org urls
			    {nomatch, "\\.apache\\..+/dist/"},
			    {nomatch, "/snapshots/"},
			    {nomatch, "^http://mail-archives"},
			    {nomatch, "bugs.+/.+"},
			    %% apache mirror sites.. TODO
			    {nomatch, "apache\\.fastbull\\.org/.+"},
			    
			    %% Skipping unwanted files
			    {nomatch, "\\.deb$"},
			    {nomatch, "\\.git$"},
			    {nomatch, "\\.tgz"},
			    {nomatch, "\\.jar$"},
			    {nomatch, "\\.rpm$"},
			    {nomatch, "\\.tar\\.gz"},
			    
			    % Skipping CVS repositories
			    {nomatch, "/cvs/\\."},

			    %% Skipping Github unseful pages
			    {nomatch, "github\\.+/issues"},
			    {nomatch, "gist\\.github\\.com"},
			    %% the page gives incomplete header
			    {nomatch, "svn\\.github\\.com"},
			    
			    %% Skipping Gitorious unseful pages
			    {nomatch, "git.+/merge_requests/"},
			    {nomatch, "git.+/commits/"},
			    {nomatch, "git.+/trees/"},
			    
			    %% Skipping Git repositories	  		
			    {nomatch, "git.+/commit/"},
			    {nomatch, "git.+/tree/"},

			    %% Skipping HG repositories
			    {nomatch, "/changeset/"},

			    %% Skipping SVN repositories
			    {nomatch, "svn.+/viewvc/.+/"},
			    {nomatch, "http://svn\\."},
			    {nomatch, "/branches"},
			    {nomatch, "/trunk"},
			    {nomatch, "/tags"}
			   ]},

	 %% -------------------------------------------------------------------------------------------------
	 %% url_any_regexp
	 %% -------------------------------------------------------------------------------------------------
	 %%
	 %% the url will be analyzed if at least one regexp will be satisfied
	 %% at least one regexp must be defined, for instance
	 %	{match,"."}
	 
	 {url_any_regexps, [
			    {match, "apache\\.org"},
			    {match, "freshmeat\\.net"},
			    {match, "github\\.com"},
			    {match, "code\\.google\\.com"},
			    {match, "sourceforge\\.net"},
			    {match, "ohloh\\.net"},
			    {match, "bitbucket\\.org"}
			    % {nomatch, "\\.com"},
			    % {match, "\\.org"},
			    % {match, "\\.net"}
			   ]
	 },

	 %% -------------------------------------------------------------------------------------------------
	 %% obsolete_urls_after_day
	 %% -------------------------------------------------------------------------------------------------
	 %%
	 %% after how many days, an ur that is stored in the DB will become obsolete
	 
	 {obsolete_urls_after_days, 1},

	 %% -------------------------------------------------------------------------------------------------
	 %% save_referrals
	 %% -------------------------------------------------------------------------------------------------
	 %%
	 %% (cumulable) values: external, domain, subdomain 
	 %%
	 %% domain: means same domain, 
	 %% es: true  <= http://www.redaelli.org/a and http://www.redaelli.org/
	 %%     false <= http://www.redaelli.org/a and http://redaelli.org/
	 %%
	 %% subdomain: means same main domain but not same domain, 
	 %% es: false <= http://www.redaelli.org/a and http://www.redaelli.org/
	 %%     true  <= http://www.redaelli.org/a and http://redaelli.org/
	 %%
	 %% external: means samenot same domain and not same main domain 
	 %% es: false <= http://www.redaelli.org/a and http://www.redaelli.org/
	 %%     false <= http://www.redaelli.org/a and http://redaelli.org/
	 %%     true  <=  http://www.redaelli.org/a and http://matteoredaelli.wordpress.com/
	 
	 {save_referrals, [external]},
	 
	 %% -------------------------------------------------------------------------------------------------
	 %% send_body_to_mq
	 %% -------------------------------------------------------------------------------------------------
	 %%
	 %% if you need to run custom functions over the body of visited urls
	 %% you can set this parameter to true, and then create a AMQP consumer
	 %% that can read the {url, body} from the processed queue, analyze then and then (eventually) update 
	 %% the db with the new custom info 
	 
	 {send_body_to_mq, false},

	 %% -------------------------------------------------------------------------------------------------
	 %% crawlers_pool
	 %% -------------------------------------------------------------------------------------------------
	 %%
	 %% how many crawler threads will be started for each candidated url queue/depth
	 %% {crawler_pools, [{0,3},{1,2},{2,1}]} means
	 %% 3 crawlers will analyze urls got from AMQP queue ebot.new.0 that countains urls with depth==0 
	 %%   (ex. http://www.redaelli.org, http://www.redaelli.org/index.html)
	 %% 2 crawlers will analyze urls got from AMQP queue ebot.new.1 that countains urls with depth==1
	 %%   (ex. http://www.redaelli.org/matteo/, http://www.redaelli.org/matteo/index.html)
	 %% 1 crawlers will analyze urls got from AMQP queue ebot.new.2 that countains urls with depth==2

	 {crawler_pools, [{0,4}, {1,2}, {2,1}] },
	 
	 %% -------------------------------------------------------------------------------------------------
	 %% start_crawlers_at_boot
	 %% -------------------------------------------------------------------------------------------------
	 %%
	 %% are the crawlers started automatically at boot time? 
	 {start_crawlers_at_boot, true},

	 %% -------------------------------------------------------------------------------------------------
	 %% crawlers_sleep_time
	 %% -------------------------------------------------------------------------------------------------
	 %%
	 %% how many milliseconds will each crawler sleep between two url crawls?
	 %% this option is useful in order to avoid heavy workloads to teh visited sites
	 %% and for the ebot system if the hardware is not powerful enough

	 {crawlers_sleep_time, 10}
		 
	]
 }
].
